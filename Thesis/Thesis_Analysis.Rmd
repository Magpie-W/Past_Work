---
title: "MA Analysis"
author: "Magpie Winslow"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Preliminary

```{r libraries}
library(tidyverse)
library(pracma)
library(ggpubr)
```

```{r Variable Names}
Responses <- c("YY", "YN", "NY", "NN") #List of potential response patterns to label columns.

Responses1 <- paste(Responses, "1", sep = ".")
Responses2 <- paste(Responses, "2", sep = ".")
Responses3 <- paste(Responses, "3", sep = ".")

Responses12 <- append(Responses1, Responses2)
Responses13 <- append(Responses1, Responses3)
Responses23 <- append(Responses2, Responses3)

Responses123 <- append(Responses12, Responses3)
```

## Custom functions

Below is a legend for the different functions and a short synopsis for how they work.

`JABApprox.1` JAB Approximation: Converts significance values to Bayes factors using the piecewise function, based on the work described in Wagenmakers* (2022).

`TP` Total Probability: When given the probabilities for two yes or no questions, as well as their conditional probabilities when answered in sequence, it calculates the total probability for each response to the second questions according to tradition, set-based probability theory. It fairly simply applies the law of total probability to the data. **NOTE!** It requires that the data be provided in a very specific manner.

`Theta.Value`: This calculates the theta value for a pair of questions as defined in Wang (2013)**. It simply applies the definition from the to the data, with the total probability being calculated using `TP`. NOTE! this test has not been validated and provided inconsistent results and thus was not included in the final analysis.

`GetNum` Get Number of a specific response: When provided with a variable and one of the response options for that variable, it calculates the number of times that response was provided. It the total number of responses (`tot`) it provided, it calculates the total proportion of responses that gave a specific answer.

`GetNum2` Get Number of a specific response pattern in a pair of variables: Same functionality as `GetNum` however, it calculates the number of responses in the first and second responses. For instance, it will tell you the number of times people responded "Yes" to both question. `tot` works the same as in `GetNum`.

`ln`: A more data friendly version of `log()` that outputs zero for any value less than or equal to zero. Use with caution.

`chi.base` The transformation at the heart of this studies Chi^2 test: Does what it says on the tin. Useful to simplify calculations.

`chi`: Calculates the Chi^2 value for a pair of variables

`C2.Test` Chi^2 Test: Calculates the significance value and Bayes Factors for the Chi^2 test used here.

*Wagenmakers, E. J. (2022). Approximate objective Bayes factors from p-values and sample size: the 3pâˆš n rule.
**Wang, Z., & Busemeyer, J. R. (2013). A quantum question order model supported by empirical tests of an a priori and precise prediction. Topics in cognitive science, 5(4), 689-710.
```{r building-functions}

JABApprox.1 <- function(p, n){
  A <- 
    case_when(
      p <= .1 ~ 3*p*sqrt(n),
      p <= .5 & p > .1 ~ (4/3)* p^(2/3) * sqrt(n),
      p > .5 ~ p^(1/4) * sqrt(n)
    )
  
  return(A)
}

# Calculate the total probability for one condition
TP <- function(Condition){ # A condition has to be structured AY, AN, BY, BN, YY, YN, NY, NN

  names(Condition) <- c("AY", "AN", "BY", "BN", "YY", "YN", "NY", "NN")
  
  Result <- 
    Condition |>
    transmute(
      TP.Y = AY * YY + AN * NY,
      TP.N = AY * YN + AN * NN
    )
  
  return(Result)
}

# Calculate the theta values for two conditions. 
Theta.Value <- function(Condition1, Condition2){ # A condition has to be structured AY, AN, BY, BN, YY, YN, NY, NN
  
  names(Condition1) <- c("AY", "AN", "YB", "NB", "YY", "YN", "NY", "NN")
  names(Condition2) <- c("BY", "BN", "YA", "NA", "YY", "YN", "NY", "NN")
  
  TP.B <- TP(Condition1)
  TP.B <- TP.B$TP.Y
  
  TP.A <- TP(Condition2)
  TP.A <- TP.A$TP.Y
  
  I.AY <- TP.A - Condition1$AY
  I.BY <- TP.B - Condition2$BY
  
  Theta1 <- (Condition2$YY - .5*I.AY)/sqrt(Condition1$AY * Condition2$BY)
  Theta2 <- (Condition1$YY - .5*I.BY)/sqrt(Condition1$AY * Condition2$BY)
  
  Result <- data.frame(Theta1, Theta2) |> rowwise() |> mutate(DTheta = Theta2 - Theta1)
  
  return(Result)
  
}

# Get the number of times a value shows up in a variable, with the potential to normalize
GetNum <- function(Vari, value, tot = NA){
  res <- (Vari == value) |> sum(na.rm = TRUE)
  res <- case_when(
    !is.na(tot) ~ res/tot,
    .default = res
  )
  
  return(res)
}

# Get the number of times a value (or pair of values) shows up in two variables
GetNum2 <- function(Vari1, Vari2, value, v2 = value, tot = NA){
  res <- (Vari1 == value & Vari2 == v2) |> sum(na.rm = TRUE)
  res <- case_when(
    !is.na(tot) ~ res/tot,
    .default = res)
  return(res)
}

#Better log function
ln <- function(value){
  case_when(
    value == 0 ~ 0,
    .default = log(value)
  )
}

# The computation at the root of all the chi-squared tests
chi.base <- function(numb, denom){
  A <- numb * ln(numb/denom)
  return(A)
}


# Calculating the chi-squared value between two sets of variables
Chi <- function(D1, D2, n1, n2){
  GC.den <- map2(
    n1,
    n2,
    `+`
  ) |> unlist()
  
  GC <- map2(
   D1, 
   D2,
   ~chi.base((.x+.y),GC.den)
  ) |>
  reduce(`+`)
  
  GU.1 <- map(
    D1,
    ~(.x)*ln((.x)/(n1))
  ) |>
    reduce(`+`)
  
  GU.2 <- map(
    D2,
    ~(.x)*ln((.x)/(n2))
  ) |>
    reduce(`+`)

  GU <- GU.1 + GU.2

  C <- -2*(GC - GU)
  
  return(C)
  
}

# Getting the Chi-Squared Test Statistics
C2.Test <- function(D1, D2, n1, n2){
  
  Chi_Value <- Chi(D1, D2, n1, n2)
  
  DF <- length(D1) - 1
  
  p_value <- pchisq(Chi_Value, DF, lower.tail = FALSE)
  
  s = n1 + n2
  
  bayes_factor <- JABApprox.1(p_value, s)
  
  Results <- tibble(Chi_Value, p_value, bayes_factor)
  
  return(Results)
  
}

```

## Data cleaning

Data was collected in two rounds. The first round got data for conditions 1 & 2, the second round collected data for condition 3. Response variables were labeled with the character participants judged and condition the responses were collected from. For more on the experimental design, see the methods section of the "Quantum Equality in the Courtroom."

```{r Reading in Data}

Data.C1C2 <- 
  read_csv("Credibility of Order Effects_May 1, 2023_17.10.csv", 
           col_select = ends_with(c("C1", "C2"))
           )


Data.C1C2 <- Data.C1C2 |> slice(-(1:2)) |>
  mutate(across(everything(), as.numeric))

Data.C3 <- 
  read_csv("Credibility of Order Effects_June 7, 2023_17.07.csv",
           col_types = cols(
             `Mary C3` = col_factor(),
             `Bill C3` = col_factor(),
             `Alex C3` = col_factor(),
             `Dakota C3` = col_factor(),
             `Frank C3` = col_factor(),
             `Alice C3` = col_factor())
           )|>
  filter(str_starts(StartDate, "5/25/23")) |>
  select(c("Mary C3", "Bill C3", "Alex C3", "Dakota C3", "Frank C3", "Alice C3"))

head(Data.C1C2)
head(Data.C3)
```

```{r Seperating by Vignette and Condition}

Mary.Bill <- Data.C1C2 |>
  select(`Mary C1`, `Bill C1`, `Bill C2`, `Mary C2`) |>
  rename(
    M1 = `Mary C1`,
    B1 = `Bill C1`,
    B2 = `Bill C2`,
    M2 = `Mary C2`)

M.B.3 <- Data.C3 |>
  select(`Mary C3`, `Bill C3`) |>
  rename(
    M3 = `Mary C3`,
    B3 = `Bill C3`)

head(Mary.Bill)

Alex.Dakota <- Data.C1C2 |> 
  select(`Alex C1`, `Dakota C1`, `Dakota C2`, `Alex C2`) |>
  rename(
    AX1 = `Alex C1`,
    D1 = `Dakota C1`,
    D2 = `Dakota C2`,
    AX2 = `Alex C2`)

AX.D.3 <- Data.C3 |>
  select(`Alex C3`, `Dakota C3`) |>
  rename(
    AX3 = `Alex C3`,
    D3 = `Dakota C3`)

head(Alex.Dakota)

Frank.Alice <- Data.C1C2 |> 
  select(`Frank C1`, `Alice C1`, `Alice C2`, `Frank C2`) |>
  rename(
    F1 = `Frank C1`,
    AC1 = `Alice C1`,
    AC2 = `Alice C2`,
    F2 = `Frank C2`)

F.AC.3 <- Data.C3 |>
  select(`Frank C3`, `Alice C3`) |>
  rename(
    F3 = `Frank C3`,
    AC3 = `Alice C3`)

head(Frank.Alice)
```

```{r Counting Responses}

#Responses for each character individually split

M.1 <- map(c(1,2), ~GetNum(Mary.Bill$M1, .x)) |> unlist()
B.1 <- map(c(1,2), ~GetNum(Mary.Bill$B1, .x)) |> unlist()
M.2 <- map(c(1,2), ~GetNum(Mary.Bill$M2, .x)) |> unlist()
B.2 <- map(c(1,2), ~GetNum(Mary.Bill$B2, .x)) |> unlist()
M.3 <- map(c(1,2), ~GetNum(M.B.3$M3, .x)) |> unlist()
B.3 <- map(c(1,2), ~GetNum(M.B.3$B3, .x)) |> unlist()

AX.1 <- map(c(1,2), ~GetNum(Alex.Dakota$AX1, .x)) |> unlist()
D.1 <- map(c(1,2), ~GetNum(Alex.Dakota$D1, .x)) |> unlist()
AX.2 <- map(c(1,2), ~GetNum(Alex.Dakota$AX2, .x)) |> unlist()
D.2 <- map(c(1,2), ~GetNum(Alex.Dakota$D2, .x)) |> unlist()
AX.3 <- map(c(1,2), ~GetNum(AX.D.3$AX3, .x)) |> unlist()
D.3 <- map(c(1,2), ~GetNum(AX.D.3$D3, .x)) |> unlist()

F.1 <- map(c(1,2), ~GetNum(Frank.Alice$F1, .x)) |> unlist()
AC.1 <- map(c(1,2), ~GetNum(Frank.Alice$AC1, .x)) |> unlist()
F.2 <- map(c(1,2), ~GetNum(Frank.Alice$F2, .x)) |> unlist()
AC.2 <- map(c(1,2), ~GetNum(Frank.Alice$AC2, .x)) |> unlist()
F.3 <- map(c(1,2), ~GetNum(F.AC.3$F3, .x)) |> unlist()
AC.3 <- map(c(1,2), ~GetNum(F.AC.3$AC3, .x)) |> unlist()

Singles <- tibble(M.1, M.2, M.3, B.1, B.2, B.3, AX.1, AX.2, AX.3, D.1, D.2, D.3, AC.1, AC.2, AC.3, F.1, F.2, F.3)
Singles

# Responses for each vignette 

MB1 <- map2(c(1,1,2,2),c(1,2,1,2), ~GetNum2(Mary.Bill$M1, Mary.Bill$B1, .x, .y)) |> unlist()
MB2 <- map2(c(1,1,2,2),c(1,2,1,2), ~GetNum2(Mary.Bill$B2, Mary.Bill$M2, .x, .y)) |> unlist()
MB3 <- map2(c(1,1,2,2),c(1,2,1,2), ~GetNum2(M.B.3$M3, M.B.3$B3, .x, .y)) |> unlist()
MB <- c(MB1, MB2, MB3)

AD1 <- map2(c(1,1,2,2),c(1,2,1,2), ~GetNum2(Alex.Dakota$AX1, Alex.Dakota$D1, .x, .y)) |> unlist()
AD2 <- map2(c(1,1,2,2),c(1,2,1,2), ~GetNum2(Alex.Dakota$D2, Alex.Dakota$AX2, .x, .y)) |> unlist()
AD3 <- map2(c(1,1,2,2),c(1,2,1,2), ~GetNum2(AX.D.3$AX3, AX.D.3$D3, .x, .y)) |> unlist()
AD <- c(AD1, AD2, AD3)

FA1 <- map2(c(1,1,2,2),c(1,2,1,2), ~GetNum2(Frank.Alice$F1, Frank.Alice$AC1, .x, .y)) |> unlist()
FA2 <- map2(c(1,1,2,2),c(1,2,1,2), ~GetNum2(Frank.Alice$AC2, Frank.Alice$F2, .x, .y)) |> unlist()
FA3 <- map2(c(1,1,2,2),c(1,2,1,2), ~GetNum2(F.AC.3$F3, F.AC.3$AC3, .x, .y)) |> unlist()
FA <- c(FA1, FA2, FA3)

# Compiling data
Data.label <- tibble(MB,AD,FA) |> t()
colnames(Data.label) <- Responses123
Data.label
Data <- Data.label |> as_tibble() |> rowwise() |>
  mutate(
    s.1 = sum(c_across(ends_with("1"))), #Number of responses
    s.2 = sum(c_across(ends_with("2"))),
    s.3 = sum(c_across(ends_with("3"))),
    
    Major.1 = YY.1 + NN.1, # Calculating both sides of the QQ Equality.
    Major.2 = YY.2 + NN.2,
    Major.3 = YY.3 + NN.3,
    
    minor.1 = YN.1 + NY.1,
    minor.2 = YN.2 + NY.2,
    minor.3 = YN.3 + NY.3
  )

Data

```

```{r Splitting by Condition and Type}

Data.C1 <- Data |>
  select(ends_with("1"))

Singles.C1 <- Singles |>
  select(ends_with("1"))

Data.C2 <- Data |>
  select(ends_with("2"))

Singles.C2 <- Singles |>
  select(ends_with("2"))

Data.C3 <- Data |>
  select(ends_with("3"))

Singles.C3 <- Singles |>
  select(ends_with("3"))

Data.QQ <- Data |> # Data to test the QQ equality
  select(starts_with("M"))


Data.Responses.1 <- Data.C1 |> 
  select(starts_with("Y") | starts_with("N"))

Data.Responses.2 <- Data.C2 |> 
  select(all_of(c("YY.2", "NY.2", "YN.2", "NN.2")))

Data.Responses.3 <- Data.C3 |> 
  select(starts_with("Y") | starts_with("N"))


Data.Q.1 <- Data.C1 |> 
  select(starts_with("m"))
  
Data.Q.2 <- Data.C2 |> 
  select(starts_with("m"))
  
Data.Q.3 <- Data.C3 |> 
  select(starts_with("m"))
  

head(Data.C1)
head(Data.C2)
head(Data.C3)
head(Data.QQ)
head(Data.Q.1)
head(Data.Q.2)
head(Data.Q.3)

```

```{r Singles formated for Theta}

All_Data <- list(Mary.Bill, M.B.3, Alex.Dakota, AX.D.3, Frank.Alice, F.AC.3) 

AY <- map(All_Data, ~GetNum(select(.x, any_of(c("M1","AX1","F1"))), 1, tot = 500)) |> 
  discard(\(x) x == 0) |>
  unlist()

AN <- map(All_Data, ~GetNum(select(.x, any_of(c("M1","AX1","F1"))), 2, tot = 500)) |> 
  discard(\(x) x == 0) |>
  unlist()

YB <- map(All_Data, ~GetNum(select(.x, any_of(c("B1","D1","AC1"))), 1, tot = 500)) |> 
  discard(\(x) x == 0) |>
  unlist()

NB <- map(All_Data, ~GetNum(select(.x, any_of(c("B1","D1","AC1"))), 2, tot = 500)) |> 
  discard(\(x) x == 0) |>
  unlist()

BY <- map(All_Data, ~GetNum(select(.x, any_of(c("B2","D2","AC2"))), 1, tot = 496)) |> 
  discard(\(x) x == 0) |>
  unlist()

BN <- map(All_Data, ~GetNum(select(.x, any_of(c("B2","D2","AC2"))), 2, tot = 496)) |> 
  discard(\(x) x == 0) |>
  unlist()

YA <- map(All_Data, ~GetNum(select(.x, any_of(c("M2","AX2","F2"))), 1, tot = 496)) |> 
  discard(\(x) x == 0) |>
  unlist()

nA <- map(All_Data, ~GetNum(select(.x, any_of(c("M2","AX2","F2"))), 2, tot = 496)) |> 
  discard(\(x) x == 0) |>
  unlist()

AY.alt <- map(All_Data, ~GetNum(select(.x, any_of(c("M3","AX3","F3"))), 1, tot = 496)) |> 
  discard(\(x) x == 0) |>
  unlist()

AN.alt <- map(All_Data, ~GetNum(select(.x, any_of(c("M3","AX3","F3"))), 2, tot = 495)) |> 
  discard(\(x) x == 0) |>
  unlist()

YB.alt <- map(All_Data, ~GetNum(select(.x, any_of(c("B3","D3","AC3"))), 1, tot = 495)) |> 
  discard(\(x) x == 0) |>
  unlist()

NB.alt <- map(All_Data, ~GetNum(select(.x, any_of(c("B3","D3","AC3"))), 2, tot = 495)) |> 
  discard(\(x) x == 0) |>
  unlist()

Data.Responses.1.norm <- Data.C1 |> 
  mutate( across(all_of(Responses1))/s.1 ) |>
  select(starts_with("Y") | starts_with("N"))

Data.Responses.2.norm <- Data.C2 |> 
  mutate( across(all_of(Responses2))/s.2 ) |>
  select(starts_with("Y") | starts_with("N"))

Data.Responses.3.norm <- Data.C3 |> 
  mutate( across(all_of(Responses3))/s.3 ) |>
  select(starts_with("Y") | starts_with("N"))

Condition1 <- cbind(AY,AN,YB,NB,Data.Responses.1.norm) |> rowwise()

Condition2 <- cbind(BY,BN,YA,nA,Data.Responses.2.norm) |> rowwise()

Condition3 <- cbind(AY.alt,AN.alt,YB.alt,NB.alt,Data.Responses.3.norm)

Condition1
Condition2
Condition3

```

# Summary Analysis

## Conditions 1 and 2

```{r Testing Order Effects and QQ Equality}

print("Conditions 1 and 2")

C2.Test(Data.Responses.1, Data.Responses.2, Data.C1$s.1, Data.C2$s.2) |> 
  mutate(
    bayes_factor_10 = 1/bayes_factor
  )

C2.Test(Data.Q.1, Data.Q.2, Data.C1$s.1, Data.C2$s.2) |> 
  mutate(
    bayes_factor_10 = 1/bayes_factor
  )

Theta.Value(Condition1, Condition2)

```

## Conditions 1 and 3

```{r}

print("Conditions 1 and 3")

C2.Test(Data.Responses.1, Data.Responses.3, Data.C1$s.1, Data.C3$s.3)|> 
  mutate(
    bayes_factor_10 = 1/bayes_factor
  )

C2.Test(Data.Q.1, Data.Q.3, Data.C1$s.1, Data.C3$s.3)|> 
  mutate(
    bayes_factor_10 = 1/bayes_factor
  )

Theta.Value(Condition1, Condition3)

```

## Conditions 2 and 3

```{r}

print("Conditions 2 and 3")

C2.Test(Data.Responses.2, Data.Responses.3, Data.C2$s.2, Data.C3$s.3)

C2.Test(Data.Q.2, Data.Q.3, Data.C2$s.2, Data.C3$s.3)

Theta.Value(Condition2, Condition3)

```

# Subsampling

```{r function-preliminaries}

subs <- 100 #Number of subsamples to calculate
samp <- 200 #Sample size for each subsample.


SubSample <- function(DD, n_subs, n_samp){ #A function to subsample the data
  
  pop <- 1:nrow(DD) #List of people in the full sample.
  
  res <- list()
  
  for(i in 1:n_subs){
    
    SS <- sample(pop, n_samp, replace = TRUE) # Randomly select participants for the subsample, with replacement
    SS <- DD[SS,] # Convert that "list" of people into a dataframe of responses
    
    res[[i]] <- SS # Add that subsample of responses to the total list of responses
    
  } # Repeat for the requested number of subsamples. 
  
  return(res)
  
}

```

## Getting the Data

```{r Sub Sampling each Condition}

C1.SS <- All_Data |> # Summon the list of all responses.
  map(\(x) select(x,ends_with("1"))) |> # Select only the variables from the first condition.
  discard(\(x) ncol(x) == 0) |>  # Drop any empty list elements
  map(~drop_na(.x)) |> # Drop all "NA" values
  map(~SubSample(.x,subs,samp))  # Subsample the data 

names(C1.SS) <- c("Mary.Bill", "Alex.Dakota", "Frank.Alice") # Rename sensibly

C2.SS <- All_Data |> # Repeat above for Condition 2
  map(\(x) select(x,ends_with("2"))) |>
  discard(\(x) ncol(x) == 0) |> 
  map(~drop_na(.x)) |>
  map(~SubSample(.x,subs,samp)) 

names(C2.SS) <- c("Mary.Bill", "Alex.Dakota", "Frank.Alice")

C3.SS <- All_Data |> # Repeat above for Condition 3
  map(\(x) select(x,ends_with("3"))) |>
  discard(\(x) ncol(x) == 0) |> 
  map(~drop_na(.x)) |>
  map(~SubSample(.x,subs,samp)) 

names(C3.SS) <- c("Mary.Bill", "Alex.Dakota", "Frank.Alice")


#```

#```{r C1 SubSample Results}

C1.SS.ResPattern <- # Converting lists of responses into number of people in each responses pattern.
  C1.SS |> # This data is structured as a list containing three lists, each of this second layer of lists contain dataframes.
    map_depth(2,  # Look at the second layer of lists and select a dataframe
      \(z) map2( 
        c(1,1,2,2), # Calculate the number of responses in the following order: Yes-Yes, Yes-No, No-Yes, No-No
        c(1,2,1,2),
        \(x,y) reduce( # Plug that dataframe into this reduce function and get all combinations of yes and no responses 
          z, \(v,w) GetNum2(v,w,x,y)
        )
      )
    ) |>
  map_depth(2, unlist) |> # Turn those lists of yes/no responses into a single vector
  map(\(z) reduce(z, ~cbind(.x,.y))) |> # combine those vectors into a single dataframe
  map(~t(.x)) |> # Rotate it to make each column a response pattern and each row a subsample.
  map(~as_tibble(.x)) |> # Make them nice to work with
  map(\(x) rename(x, "YY" = "V1", "YN" = "V2", "NY" = "V3", "NN" = "V4")) |> map(rowwise) |> # Give everything meaningful names
  map( \(x) mutate(x, s.1 = YY + NN + YN + NY)) # Calculate the total number of responses for each subsample (it should be `samp`, but just in case.)
# The end results is a list of three dataframes, one for each vignette.
C1.SS.Q <- C1.SS.ResPattern |> 
  map(\(z) transmute(z, QMajor = YY + NN, Qminor = YN + NY, s.1 = s.1) ) # Calculate the two different components for the different versions of the QQ Equality

C1.SS.Singles <- C1.SS |> map_depth(2, # Instead of calculating the number of responses for pairs of variables, just do it for each variable.
  \(y) map(y,
    \(z) map(
      c(1,2), # Calculates the Yes values first
      ~GetNum(z,.x, tot = samp)) |> unlist()
    )
  )

AY.ss <- C1.SS.Singles |> 
  map_depth(2,\(z) pluck(z,1,1)) |> # Get only the number of yes responses for the first question
  map(unlist) |> # Convert to a vector
  map(\(z) as_tibble_col(z, column_name = "AY")) # Converet that vector into a column fo a dataframe called AY
AN.ss <- C1.SS.Singles |> # Same as above for the no responses to the first question
  map_depth(2,\(z) pluck(z,1,2)) |>
  map(unlist) |>
  map(\(z) as_tibble_col(z, column_name = "AN"))
YB.ss <- C1.SS.Singles |> # Same as above for the yes responses to the second question
  map_depth(2,\(z) pluck(z,2,1)) |>
  map(unlist) |>
  map(\(z) as_tibble_col(z, column_name = "YB"))
NB.ss <- C1.SS.Singles |> # No responses for the second question. 
  map_depth(2,\(z) pluck(z,2,2)) |>
  map(unlist) |>
  map(\(z) as_tibble_col(z, column_name = "NB"))

Condition1.ss <- C1.SS.ResPattern |> 
  map(\(z) mutate(z, across(all_of(Responses))/s.1)) |> 
  map(\(z) select(z,all_of(Responses)))

Condition1.ss <- list(ay = AY.ss, an = AN.ss, yb = YB.ss, nb = NB.ss, combined = Condition1.ss) |> 
  pmap(\(ay, an, yb, nb, combined) cbind(ay, an, yb, nb, combined) )

Condition1.ss
#```

#```{r Summarizing C2}

C2.SS.ResPattern <- 
  C2.SS |> #This gets complicated
    map_depth(2,  #We are dealing with lists of lists
      \(z) map2( #Select a dataframe from a nested list
        c(1,2,1,2),
        c(1,1,2,2),
        \(x,y) reduce( # Plug that dataframe into this reduce function and get all combinations of yes and no responses 
          z, \(v,w) GetNum2(v,w,x,y)
        )
      )
    ) |>
  map_depth(2, unlist) |> # Turn those lists of yes/no responses into a single vector
  map(\(z) reduce(z, ~cbind(.x,.y))) |> # combine those vectors into matrices
  map(~t(.x)) |> # Rotate to make sensible
  map(~as_tibble(.x)) |> # Make them nice to work with
  map(\(x) rename(x, "YY" = "V1", "NY" = "V2", "YN" = "V3", "NN" = "V4")) |> map(rowwise) |> # Name them something sensible.
  map( \(x) mutate(x, s.2 = YY + NN + YN + NY))

C2.SS.Singles <- C2.SS |> map_depth(2, 
  \(y) map(y,
    \(z) map(
      c(1,2),
      ~GetNum(z,.x, tot = samp)) |> unlist()
    )
  )

C2.SS.Q <- C2.SS.ResPattern |> 
  map(\(z) transmute(z, QMajor = YY + NN, Qminor = YN + NY, s.2 = s.2) )

BY.ss <- C2.SS.Singles |> 
  map_depth(2,\(z) pluck(z,1,1)) |>
  map(unlist) |>
  map(\(z) as_tibble_col(z, column_name = "BY"))
BN.ss <- C2.SS.Singles |> 
  map_depth(2,\(z) pluck(z,1,2)) |>
  map(unlist) |>
  map(\(z) as_tibble_col(z, column_name = "BN"))
YA.ss <- C2.SS.Singles |> 
  map_depth(2,\(z) pluck(z,2,1)) |>
  map(unlist) |>
  map(\(z) as_tibble_col(z, column_name = "YA"))
nA.ss <- C2.SS.Singles |> 
  map_depth(2,\(z) pluck(z,2,2)) |>
  map(unlist) |>
  map(\(z) as_tibble_col(z, column_name = "nA"))

Condition2.ss <- C2.SS.ResPattern |> 
  map(\(z) mutate(z, across(all_of(Responses))/s.2)) |> 
  map(\(z) select(z,all_of(Responses)))

Condition2.ss <- list(by = BY.ss, bn = BN.ss, ya = YA.ss, na = nA.ss, combined = Condition2.ss) |> 
  pmap(\(by, bn, ya, na, combined) cbind(by, bn, ya, na, combined) )

Condition2.ss

#```

#```{r Summarizing C3}

C3.SS.ResPattern <- 
  C3.SS |> #This gets complicated
    map_depth(2,  #We are dealing with lists of lists
      \(z) map2( #Select a dataframe from a nested list
        c(1,1,2,2), 
        c(1,2,1,2),
        \(x,y) reduce( # Plug that dataframe into this reduce function and get all combinations of yes and no responses 
          z, \(v,w) GetNum2(v,w,x,y)
        )
      )
    ) |>
  map_depth(2, unlist) |> # Turn those lists of yes/no responses into a single vector
  map(\(z) reduce(z, ~cbind(.x,.y))) |> # combine those vectors into matrices
  map(~t(.x)) |> # Rotate to make sensible
  map(~as_tibble(.x)) |> # Make them nice to work with
  map(\(x) rename(x, "YY" = "V1", "YN" = "V2", "NY" = "V3", "NN" = "V4")) |> map(rowwise) |> # Name them something sensible.
  map( \(x) mutate(x, s.3 = YY + NN + YN + NY))

C3.SS.Singles <- C3.SS |> map_depth(2, 
  \(y) map(y,
    \(z) map(
      c(1,2),
      ~GetNum(z,.x, samp)) |> unlist()
    )
  )

C3.SS.Q <- C3.SS.ResPattern |> 
  map(\(z) transmute(z, QMajor = YY + NN, Qminor = YN + NY, s.3 = s.3) )

AY.alt.ss <- C3.SS.Singles |>
  map_depth(2,\(z) pluck(z,1,1)) |> 
  map(unlist) |> 
  map(\(z) as_tibble_col(z, column_name = "AY.alt"))
AN.alt.ss <- C3.SS.Singles |>
  map_depth(2,\(z) pluck(z,1,2)) |> 
  map(unlist) |> 
  map(\(z) as_tibble_col(z, column_name = "AN.alt"))
YB.alt.ss <- C3.SS.Singles |>
  map_depth(2,\(z) pluck(z,2,1)) |> 
  map(unlist) |> 
  map(\(z) as_tibble_col(z, column_name = "YB.alt"))
NB.alt.ss <- C3.SS.Singles |>
  map_depth(2,\(z) pluck(z,2,2)) |> 
  map(unlist) |> 
  map(\(z) as_tibble_col(z, column_name = "NB.alt"))


Condition3.ss <- C3.SS.ResPattern |> 
  map(\(z) mutate(z, across(all_of(Responses))/s.3)) |> 
  map(\(z) select(z,all_of(Responses)))

Condition3.ss <- list(ay = AY.alt.ss, an = AN.alt.ss, yb = YB.alt.ss, nb = NB.alt.ss, combined = Condition3.ss) |> 
  pmap(\(ay, an, yb, nb, combined) cbind(ay, an, yb, nb, combined) )

Condition3.ss

```

```{r order/context effects}

C12.SS.Order <- map2(C1.SS.ResPattern, C2.SS.ResPattern, 
     \(u,v) map2(u,v, ~(.y - .x)) ) |> 
  map(\(u) u |> as_tibble() |> select(!s.1))

C13.SS.Order <- map2(C1.SS.ResPattern, C3.SS.ResPattern, 
     \(u,v) map2(u,v, ~(.y - .x)) ) |> 
  map(\(u) u |> as_tibble() |> select(!s.1))

C23.SS.Order <- map2(C2.SS.ResPattern, C3.SS.ResPattern, 
     \(u,v) map2(u,v, ~(.y - .x)) ) |> 
  map(\(u) u |> as_tibble() |> select(!s.2))

```

## Analysis

```{r Subsample analyses for C12}

C12.cor.Major <- 
  map(C12.SS.Order, 
     \(u) cor(u["YY"], u["NN"]) ) |> 
  map(as_tibble) |> unlist()

C12.cor.minor <- 
  map(C12.SS.Order, 
     \(u) cor(u["YN"], u["NY"]) ) |> 
  map(as_tibble) |> unlist()

C12.cor.Major

C12.cor.minor

```
```{r Mary-Bill correlation tests for C12}
cor.test(C12.SS.Order$Mary.Bill$YY, C12.SS.Order$Mary.Bill$NN)
cor.test(C12.SS.Order$Mary.Bill$YN, C12.SS.Order$Mary.Bill$NY)
```
```{r Alex-Dakota correlation tests for C12}
cor.test(C12.SS.Order$Alex.Dakota$YY, C12.SS.Order$Alex.Dakota$NN)
cor.test(C12.SS.Order$Alex.Dakota$YN, C12.SS.Order$Alex.Dakota$NY)

```
```{r Frank-Alice correlation tests for C12}
cor.test(C12.SS.Order$Frank.Alice$YY, C12.SS.Order$Frank.Alice$NN)
cor.test(C12.SS.Order$Frank.Alice$YN, C12.SS.Order$Frank.Alice$NY)

```

```{r Subsample analyses for C13}

C13.cor.Major <- 
  map(C13.SS.Order, 
     \(u) cor(u["YY"], u["NN"]) ) |> 
  map(as_tibble) |> unlist()

C13.cor.minor <- 
  map(C13.SS.Order, 
     \(u) cor(u["YN"], u["NY"]) ) |> 
  map(as_tibble) |> unlist()

C13.cor.Major
C13.cor.minor

```
```{r Mary-Bill correlation tests for C13}
cor.test(C13.SS.Order$Mary.Bill$YY, C13.SS.Order$Mary.Bill$NN)
cor.test(C13.SS.Order$Mary.Bill$YN, C13.SS.Order$Mary.Bill$NY)
```
```{r Alex-Dakota correlation tests for C13}
cor.test(C13.SS.Order$Alex.Dakota$YY, C13.SS.Order$Alex.Dakota$NN)
cor.test(C13.SS.Order$Alex.Dakota$YN, C13.SS.Order$Alex.Dakota$NY)
```
```{r Frank-Alice correlation tests for C13}
cor.test(C13.SS.Order$Frank.Alice$YY, C13.SS.Order$Frank.Alice$NN)
cor.test(C13.SS.Order$Frank.Alice$YN, C13.SS.Order$Frank.Alice$NY)
```

```{r Correlation for C23}

C23.cor.Major <- 
  map(C23.SS.Order, 
     \(u) cor(u["YY"], u["NN"]) ) |> 
  map(as_tibble) |> unlist()

C23.cor.minor <- 
  map(C23.SS.Order, 
     \(u) cor(u["YN"], u["NY"]) ) |> 
  map(as_tibble) |> unlist()

C23.cor.Major
C23.cor.minor

```

### Distance Tests

```{r C12 Distance test minor}

C12.SS.Order.minor <- C12.SS.Order |>
  map(\(u) u |> select(YN, NY)) 

C12.SS.Order.minor |> 
  map(
    \(u) u |> 
      mutate(D = sqrt(YN^2 + NY^2)) |> #Calculate the distance of each pair of order effects from the origin
      summarise(
        Mean.YN = mean(YN), 
        SD.YN = sd(YN), 
        Mean.NY = mean(NY), 
        SD.NY = sd(NY),
        Mean.D = mean(D), # Average distance from the origin
        SD.D = sd(D), # Variation in distance
        x2.SD.D = SD.D*2, # Bounds of 95% of data points.
        D.of.Mean = sqrt(Mean.YN^2+ Mean.NY^2), # Distance from the origin of the average pair of minor response pattern order effects, treated as the approximate center of mass for the data.
        n = n(),
        )
  )

C12.SS.Order.minor |> 
  map_depth(1,
    \(u) u |> 
      mutate(D.from.Mean = sqrt((YN-mean(YN))^2 + (NY-mean(NY))^2)) |> #The distance of each pair of order effects from the average for that response option (ie the center of mass or COM).
      summarise(
        Mean.YN = mean(YN), 
        Mean.NY = mean(NY), 
        D.of.Mean = sqrt(Mean.YN^2+ Mean.NY^2),
        Mean.D = mean(D.from.Mean), #Average distance from COM
        SD.D = sd(D.from.Mean), # Variation in distance from COM
        x2.SD.D = SD.D*2, # 95% range of distance from COM
        Mode.D = Mode(D.from.Mean)
        ) 
  )

C12.SS.Order.minor |> # Calculating the percent of data farther away from the COM than the origin.
  map_depth(1,
    \(u) u |> 
      mutate(
        D.from.Mean = sqrt((YN-mean(YN))^2 + (NY-mean(NY))^2),
        GT.DoMean = D.from.Mean > sqrt((mean(YN))^2 + (mean(NY))^2)
      ) |>
      summarise(
        D.of.Means = sqrt((mean(YN))^2 + (mean(NY))^2),
        Mean.D = mean(D.from.Mean),
        SD.D = sd(D.from.Mean),
        Percent.GT.DoM = sum(GT.DoMean)
      )
  )

C12.SS.Order.minor |> # Plotting data.
  map_depth(1,
    \(u) u |> 
      mutate(
        D.from.Mean = sqrt((YY-mean(YY))^2 + (NN-mean(NN))^2),
        GT.DoMean = D.from.Mean > sqrt((mean(YY))^2 + (mean(NN))^2)
      ) |>
      ggplot(mapping = aes(x = D.from.Mean)) + geom_histogram()
  )

```

```{r C12 Distance test Major}
# Repeat of above but for Major response option pairs.
C12.SS.Order.Major <- C12.SS.Order |>
  map(\(u) u |> select(YY, NN))

C12.SS.Order.Major |> 
  map_depth(1,
    \(u) u |> 
      mutate(D = sqrt(YY^2 + NN^2)) |>
      summarise(
        Mean.YY = mean(YY), 
        SD.YY = sd(YY), 
        Mean.NN = mean(NN), 
        SD.NN = sd(NN),
        Mean.D = mean(D),
        SD.D = sd(D),
        x2.SD.D = SD.D*2,
        D.of.Mean = sqrt(Mean.YY^2 + Mean.NN^2),
        n = n(),
        )
  )


C12.SS.Order.Major |> 
  map_depth(1,
    \(u) u |> 
      mutate(D.from.Mean = sqrt((YY-mean(YY))^2 + (NN-mean(NN))^2)) |>
      summarise(
        Mean.YY = mean(YY), 
        Mean.NN = mean(NN), 
        D.of.Mean = sqrt(Mean.YY^2+ Mean.NN^2),
        Mean.D = mean(D.from.Mean),
        SD.D = sd(D.from.Mean),
        x2.SD.D = SD.D*2,
        Mode.D = Mode(D.from.Mean)
        ) 
  )

C12.SS.Order.Major |> 
  map_depth(1,
    \(u) u |> 
      mutate(
        D.from.Mean = sqrt((YY-mean(YY))^2 + (NN-mean(NN))^2),
        GT.DoMean = D.from.Mean > sqrt((mean(YY))^2 + (mean(NN))^2)
      ) |>
      summarise(
        D.of.Means = sqrt((mean(YY))^2 + (mean(NN))^2),
        Mean.D = mean(D.from.Mean),
        SD.D = sd(D.from.Mean),
        Percent.GT.DoM = sum(GT.DoMean)
      )
  )

C12.SS.Order.Major |> 
  map_depth(1,
    \(u) u |> 
      mutate(
        D.from.Mean = sqrt((YY-mean(YY))^2 + (NN-mean(NN))^2),
        GT.DoMean = D.from.Mean > sqrt((mean(YY))^2 + (mean(NN))^2)
      ) |>
      ggplot(mapping = aes(x = D.from.Mean)) + geom_histogram()
  )
```

```{r C13 Distance Test minor}
C13.SS.Order.minor <- C13.SS.Order |>
  map(\(u) u |> select(YN, NY))

C13.SS.Order.minor |> 
  map_depth(1,
    \(u) u |> 
      mutate(D = sqrt(YN^2 + NY^2)) |>
      summarise(
        Mean.YN = mean(YN), 
        SD.YN = sd(YN), 
        Mean.NY = mean(NY), 
        SD.NY = sd(NY),
        Mean.D = mean(D),
        SD.D = sd(D),
        x2.SD.D = SD.D*2,
        D.of.Mean = sqrt(Mean.YN^2 + Mean.NY^2),
        n = n(),
        ) |>
      select(D.of.Mean, SD.D, x2.SD.D)
  )

C13.SS.Order.minor |> 
  map_depth(1,
    \(u) u |> 
      mutate(D.from.Mean = sqrt((YN-mean(YN))^2 + (NY-mean(NY))^2)) |>
      summarise(
        Mean.YN = mean(YN), 
        Mean.NY = mean(NY), 
        D.of.Mean = sqrt(Mean.YN^2+ Mean.NY^2),
        Mean.D = mean(D.from.Mean),
        SD.D = sd(D.from.Mean),
        x2.SD.D = SD.D*2,
        Mode.D = Mode(D.from.Mean)
        ) 
  )

C13.SS.Order.minor |> 
  map_depth(1,
    \(u) u |> 
      mutate(
        D.from.Mean = sqrt((YN-mean(YN))^2 + (NY-mean(NY))^2),
        GT.DoMean = D.from.Mean > sqrt((mean(YN))^2 + (mean(NY))^2)
      ) |>
      summarise(
        D.of.Means = sqrt((mean(YN))^2 + (mean(NY))^2),
        Mean.D = mean(D.from.Mean),
        SD.D = sd(D.from.Mean),
        Percent.GT.DoM = sum(GT.DoMean)
      )
  )
```

```{r C13 Distance test Major}

C13.SS.Order.Major <- C13.SS.Order |>
  map(\(u) u |> select(YY, NN))

C13.SS.Order.Major |> 
  map_depth(1,
    \(u) u |> 
      mutate(D = sqrt(YY^2 + NN^2)) |>
      summarise(
        Mean.YY = mean(YY), 
        SD.YY = sd(YY), 
        Mean.NN = mean(NN), 
        SD.NN = sd(NN),
        Mean.D = mean(D),
        SD.D = sd(D),
        D.of.Mean = sqrt(Mean.YY^2 + Mean.NN^2),
        n = n(),
        ) |>
      select(D.of.Mean, SD.D)
  )

C13.SS.Order.Major |> 
  map_depth(1,
    \(u) u |> 
      mutate(D.from.Mean = sqrt((YY-mean(YY))^2 + (NN-mean(NN))^2)) |>
      summarise(
        Mean.YY = mean(YY), 
        Mean.NN = mean(NN), 
        D.of.Mean = sqrt(Mean.YY^2+ Mean.NN^2),
        Mean.D = mean(D.from.Mean),
        SD.D = sd(D.from.Mean),
        x2.SD.D = SD.D*2,
        Mode.D = Mode(D.from.Mean)
        ) 
  )


```

## Results

```{r Mean Tables}

C12.SS.Order.Summary <- C12.SS.Order |> 
  map(
    ~summarize(
      .x, 
      YY.Mean = mean(YY), 
      YY.sd = sd(YY),
      YN.Mean = mean(YN),
      YN.sd = sd(YN),
      NY.Mean = mean(NY),
      NY.sd = sd(NY),
      NN.Mean = mean(NN),
      NN.sd = sd(NN),
    )
  ) |> reduce(rbind) |> as.data.frame()

rownames(C12.SS.Order.Summary) <- c("Mary-Bill", "Alex-Dakota", "Frank-Alice")
C12.SS.Order.Summary

C12.SS.Order |> map( \(z) map(z, ~summary(.x)))

C13.SS.Order.Summary <- C13.SS.Order |> 
  map(
    ~summarize(
      .x, 
      YY.Mean = mean(YY), 
      YY.sd = sd(YY),
      YN.Mean = mean(YN),
      YN.sd = sd(YN),
      NY.Mean = mean(NY),
      NY.sd = sd(NY),
      NN.Mean = mean(NN),
      NN.sd = sd(NN),
    )
  ) |> reduce(rbind) |> as.data.frame()

rownames(C13.SS.Order.Summary) <- c("Mary-Bill", "Alex-Dakota", "Frank-Alice")
C13.SS.Order.Summary

C13.SS.Order |> map( \(z) map(z, ~summary(.x)))

C23.SS.Order.Summary <- C23.SS.Order |> 
  map(
    ~summarize(
      .x, 
      YY.Mean = mean(YY), 
      YY.sd = sd(YY),
      YN.Mean = mean(YN),
      YN.sd = sd(YN),
      NY.Mean = mean(NY),
      NY.sd = sd(NY),
      NN.Mean = mean(NN),
      NN.sd = sd(NN),
    )
  ) |> reduce(rbind) |> as.data.frame()

rownames(C23.SS.Order.Summary) <- c("Mary-Bill", "Alex-Dakota", "Frank-Alice")
C23.SS.Order.Summary

C23.SS.Order |> map( \(z) map(z, ~summary(.x)))

```

### Correlations for Conditions 1 and 2

```{r Base order/cor plots}

C12.Order.minor.Plot <- 
  C12.SS.Order |> map( \(u)
    ggplot(u, mapping = aes(x = YN, y = NY)) +
      geom_point() +
      geom_smooth(method = lm, formula = y ~ x)+
    labs(
      x = "YN Context Effect", 
      y = "NY Context Effect"
    )
  )

C12.Order.Major.Plot <- 
  C12.SS.Order |> map( \(u)
    ggplot(u, mapping = aes(x = YY, y = NN)) +
      geom_point() +
      geom_smooth(method = lm, formula = y ~ x) +
    labs(
      x = "YY Context Effect", 
      y = "NN Context Effect"
    )
  )

C12.Order.minor.Plot
C12.cor.minor
C12.Order.Major.Plot
C12.cor.Major

```

```{r prepping data to combine into a single graphic}
C12.SS.Order.MB$s.1 <- "Mary-Bill"

C12.Order.Plot <- C12.SS.Order.MB |> rename("Vignette" = s.1)

C12.SS.Order.AD$s.1 <- "Dakota-Alex"

A <- C12.SS.Order.AD |> rename("Vignette" = s.1)

C12.Order.Plot <- bind_rows(C12.Order.Plot, A)

C12.SS.Order.FA$s.1 <- "Frank-Alice"

A <- C12.SS.Order.FA |> rename("Vignette" = s.1)

C12.Order.Plot <- bind_rows(C12.Order.Plot, A) |> group_by(Vignette)
```

```{r Full C12 Cor Plots}
C12.minor.Plot <- 
  C12.Order.Plot |> ggplot( mapping = aes(x = YN, y = NY))+
  geom_point(size = 1) +
  geom_smooth(method = lm, formula = y ~ x, color = "azure4")+
  facet_wrap(vars(Vignette), scales = "free")+
  xlab("Yes-No Context Effect")+
  ylab("No-Yes Context Effect") + 
  theme_bw()+
  theme(axis.title = element_text(face = "bold"))
  

C12.Major.Plot <- 
  C12.Order.Plot |> ggplot( mapping = aes(x = YY, y = NN))+
  geom_point(size = 1) +
  geom_smooth(method = lm, formula = y ~ x, color = "azure4")+
  facet_wrap(vars(Vignette), scales = "free")+
  xlab("Yes-Yes Context Effect")+
  ylab("No-No Context Effect")+
  theme_bw()+
  theme(axis.title = element_text(face = "bold"))
  
ggarrange(C12.Major.Plot, C12.minor.Plot, nrow = 2)

ggsave("Graphs/C12_Plots.png", height = 5)

```

### Conditions 1 and 3

```{r Base order/cor plots}

C13.Order.minor.Plot <- C13.SS.Order |> map( \(u)
  ggplot(u, mapping = aes(x = YN, y = NY)) +
    geom_point() +
    geom_smooth(method = lm, formula = y ~ x) +
    labs(
      x = "YN Context Effect", 
      y = "NY Context Effect"
    )
)

C13.Order.Major.Plot <- C13.SS.Order |> map( \(u)
  ggplot(u, mapping = aes(x = YY, y = NN)) +
    geom_point() +
    geom_smooth(method = lm, formula = y ~ x) +
    labs(
      x = "YY Context Effect", 
      y = "NN Context Effect"
    )
)

C13.Order.minor.Plot
C13.cor.minor
C13.Order.Major.Plot
C13.cor.Major

```

```{r Prepping data for final graph}
C13.SS.Order.MB$s.1 <- "Mary-Bill"

C13.Order.Plot <- C13.SS.Order.MB |> rename("Vignette" = s.1)

C13.SS.Order.AD$s.1 <- "Dakota-Alex"

A <- C13.SS.Order.AD |> rename("Vignette" = s.1)

C13.Order.Plot <- bind_rows(C13.Order.Plot, A)

C13.SS.Order.FA$s.1 <- "Frank-Alice"

A <- C13.SS.Order.FA |> rename("Vignette" = s.1)

C13.Order.Plot <- bind_rows(C13.Order.Plot, A) |> group_by(Vignette)
```

```{r Full C13 Cor Plots}
C13.minor.Plot <- 
  C13.Order.Plot |> ggplot( mapping = aes(x = YN, y = NY))+
  geom_point(size = 1) +
  geom_smooth(method = lm, formula = y ~ x, color = "azure4")+
  facet_wrap(vars(Vignette), scales = "free")+
  xlab("Yes-No Context Effect")+
  ylab("No-Yes Context Effect") + 
  theme_bw()+
  theme(axis.title = element_text(face = "bold"))
  

C13.Major.Plot <- 
  C13.Order.Plot |> ggplot( mapping = aes(x = YY, y = NN))+
  geom_point(size = 1) +
  geom_smooth(method = lm, formula = y ~ x, color = "azure4")+
  facet_wrap(vars(Vignette), scales = "free")+
  xlab("Yes-Yes Context Effect")+
  ylab("No-No Context Effect")+
  theme_bw()+
  theme(axis.title = element_text(face = "bold"))
  
ggarrange(C13.Major.Plot, C13.minor.Plot, nrow = 2)

ggsave("Graphs/C13_Plots.png", height = 5)

```


### Conditions 2 and 3

```{r Base order/cor plots}

C23.Order.minor.Plot <- C23.SS.Order |> map( \(u)
  ggplot(u, mapping = aes(x = YN, y = NY)) +
    geom_point() +
    geom_smooth(method = lm, formula = y ~ x) +
    labs(
      x = "YN Context Effect", 
      y = "NY Context Effect"
    )
)

C23.Order.Major.Plot <- C23.SS.Order |> map( \(u)
  ggplot(u, mapping = aes(x = YY, y = NN)) +
    geom_point() +
    geom_smooth(method = lm, formula = y ~ x) +
    labs(
      x = "YY Context Effect", 
      y = "NN Context Effect"
    )
)

C23.Order.minor.Plot
C23.cor.minor
C23.Order.Major.Plot 
C23.cor.Major

```

```{r Full C23 Cor Plot}
C23.SS.Order.MB <- C23.SS.Order$Mary.Bill |> as_tibble() 
C23.SS.Order.AD <- C23.SS.Order$Alex.Dakota |> as_tibble() 
C23.SS.Order.FA <- C23.SS.Order$Frank.Alice |> as_tibble() 

C23.SS.Order.MB$s.2 <- "Mary-Bill"

C23.Order.Plot <- C23.SS.Order.MB |> rename("Vignette" = s.2)

C23.SS.Order.AD$s.2 <- "Dakota-Alex"

A <- C23.SS.Order.AD |> rename("Vignette" = s.2)

C23.Order.Plot <- bind_rows(C23.Order.Plot, A)

C23.SS.Order.FA$s.2 <- "Frank-Alice"

A <- C23.SS.Order.FA |> rename("Vignette" = s.2)

C23.Order.Plot <- bind_rows(C23.Order.Plot, A) |> group_by(Vignette)

C23.minor.Plot <- 
  C23.Order.Plot |> ggplot( mapping = aes(x = YN, y = NY))+
  geom_point(size = 1) +
  geom_smooth(method = lm, formula = y ~ x, color = "azure4")+
  facet_wrap(vars(Vignette), scales = "free")+
  xlab("Yes-No Context Effect")+
  ylab("No-Yes Context Effect") + 
  theme_bw()+
  theme(axis.title = element_text(face = "bold"))
  

C13.Major.Plot <- 
  C13.Order.Plot |> ggplot( mapping = aes(x = YY, y = NN))+
  geom_point(size = 1) +
  geom_smooth(method = lm, formula = y ~ x, color = "azure4")+
  facet_wrap(vars(Vignette), scales = "free")+
  xlab("Yes-Yes Context Effect")+
  ylab("No-No Context Effect")+
  theme_bw()+
  theme(axis.title = element_text(face = "bold"))
  
ggarrange(C13.Major.Plot, C13.minor.Plot, nrow = 2)

ggsave("Graphs/C23_Plots.png", height = 5)

```

# Exporting

## Plots
```{r C12}

C12.Order.Major.Plot$Alex.Dakota+
  labs(title = "Context Effect Correlation for Alex & Dakota in Conditions 1 and 2")

ggsave("C12_Alex.Dakota_YY.NN.png", path = "/Users/maggiewinslow/Documents/Psych/MAThesis/Data/Graphs")

C12.Order.minor.Plot$Alex.Dakota+
  labs(title = "Context Effect Correlation for Alex & Dakota in Conditions 1 and 2")

ggsave("C12_Alex.Dakota_YN.NY.png", path = "/Users/maggiewinslow/Documents/Psych/MAThesis/Data/Graphs")

C12.Order.Major.Plot$Mary.Bill+
  labs(title = "Context Effect Correlation for Mary & Bill in Conditions 1 and 2")

ggsave("C12_Mary.Bill_YY.NN.png", path = "/Users/maggiewinslow/Documents/Psych/MAThesis/Data/Graphs")

C12.Order.minor.Plot$Mary.Bill+
  labs(title = "Context Effect Correlation for Mary & Bill in Conditions 1 and 2")

ggsave("C12_Mary.Bill_YN.NY.png", path = "/Users/maggiewinslow/Documents/Psych/MAThesis/Data/Graphs")

C12.Order.Major.Plot$Frank.Alice+
  labs(title = "Context Effect Correlation for Frank & Alice in Conditions 1 and 2")

ggsave("C12_Frank.Alice_YY.NN.png", path = "/Users/maggiewinslow/Documents/Psych/MAThesis/Data/Graphs")

C12.Order.minor.Plot$Frank.Alice+
  labs(title = "Context Effect Correlation for Frank & Alice in Conditions 1 and 2")

ggsave("C12_Frank.Alice_YN.NY.png", path = "/Users/maggiewinslow/Documents/Psych/MAThesis/Data/Graphs")

```

```{r C13}

C13.Order.Major.Plot$Alex.Dakota+
  labs(title = "Context Effect Correlation for Alex & Dakota in Conditions 1 and 3")

ggsave("C13_Alex.Dakota_YY.NN.png", path = "/Users/maggiewinslow/Documents/Psych/MAThesis/Data/Graphs")

C13.Order.minor.Plot$Alex.Dakota+
  labs(title = "Context Effect Correlation for Alex & Dakota in Conditions 1 and 3")

ggsave("C13_Alex.Dakota_YN.NY.png", path = "/Users/maggiewinslow/Documents/Psych/MAThesis/Data/Graphs")

C13.Order.Major.Plot$Mary.Bill+
  labs(title = "Context Effect Correlation for Mary & Bill in Conditions 1 and 3")

ggsave("C13_Mary.Bill_YY.NN.png", path = "/Users/maggiewinslow/Documents/Psych/MAThesis/Data/Graphs")

C13.Order.minor.Plot$Mary.Bill+
  labs(title = "Context Effect Correlation for Mary & Bill in Conditions 1 and 3")

ggsave("C13_Mary.Bill_YN.NY.png", path = "/Users/maggiewinslow/Documents/Psych/MAThesis/Data/Graphs")

C13.Order.Major.Plot$Frank.Alice+
  labs(title = "Context Effect Correlation for Frank & Alice in Conditions 1 and 3")

ggsave("C13_Frank.Alice_YY.NN.png", path = "/Users/maggiewinslow/Documents/Psych/MAThesis/Data/Graphs")

C13.Order.minor.Plot$Frank.Alice+
  labs(title = "Context Effect Correlation for Frank & Alice in Conditions 1 and 3")

ggsave("C13_Frank.Alice_YN.NY.png", path = "/Users/maggiewinslow/Documents/Psych/MAThesis/Data/Graphs")

```

# Demographics
## Parsing Text
```{r Reading Data}

Demographics <- 
  read_csv(
    "Credibility of Order Effects_June 7, 2023_17.07.csv",
    col_select = c(Q28_7_TEXT, Q28_8_TEXT, Q31, Q31_6_TEXT, Q31_7_TEXT, Q42)) |>
  slice(-c(1,2))

names(Demographics) <- c("gen_nl", "gen_nb", "race", "race_mix", "race_other", "age")

```
```{r gender not listed}

Demographics |> 
  filter(
    str_detect(
      gen_nl,
      regex("woman|female|afab", ignore_case = TRUE)
      )
    ) 

Demographics |> 
  filter(
    str_detect(
      gen_nl,
      regex("man|male|amab|m", ignore_case = TRUE)
      )
    ) |> 
  filter(
    !str_detect(
      gen_nl,
      regex("woman|female|afab", ignore_case = TRUE)
      )
    ) 

Demographics |> 
  filter(
    !str_detect(
      gen_nl,
      regex("man|male|amab|m", ignore_case = TRUE)
      )
    ) |> 
  filter(
    !str_detect(
      gen_nl,
      regex("woman|female|afab", ignore_case = TRUE)
      )
    ) 

```
```{r nonbinary}

Demographics$gen_nb |> as_factor() |> summary()

```
```{r bi-racial/mixed race}

Demographics |> 
  filter(
    str_detect(
      race,
      regex(",", ignore_case = TRUE)
      )
    ) 

Demographics$race_mix |> as_factor() |> summary()

```
```{r other race}

Demographics$race_other |> as_factor() |> summary()

```
```{r age}

Mode <- function(x, na.rm = FALSE) {
  
  if(na.rm){ #if na.rm is TRUE, remove NA values from input x
    x = x[!is.na(x)]
  }

  val <- unique(x)
  return(val[which.max(tabulate(match(x, val)))])
}

Demographics$age <- Demographics$age |> 
  as.double() 

Demographics$age== 330
Demographics$age[653] <- 33

Demographics$age |> Mode(na.rm = T)
```
```{r Finding totals}

Survive <- Singles |> select(starts_with("M") | starts_with("D") | starts_with("F")) |> rowwise() |> transmute(M_tot = sum(c_across(starts_with("M"))), D_tot = sum(c_across(starts_with("D"))), F_tot = sum(c_across(starts_with("F")))) |> mutate(tot = sum(c_across(everything())))

t <- sum(Survive$tot)

Survive$tot/t

t <- sum(Survive$M_tot)

Survive$M_tot/t

t <- sum(Survive$D_tot)

Survive$D_tot/t

t <- sum(Survive$F_tot)

Survive$F_tot/t

```
```{r Finding totals}

Survive <- Singles |> select(starts_with("B") | starts_with("A")) |> rowwise() |> transmute(B_tot = sum(c_across(starts_with("B"))), Ax_tot = sum(c_across(starts_with("AX"))), AC_tot = sum(c_across(starts_with("AC")))) |> mutate(tot = sum(c_across(everything())))

t <- sum(Survive$tot)

Survive$tot/t

t <- sum(Survive$B_tot)

Survive$B_tot/t

t <- sum(Survive$Ax_tot)

Survive$Ax_tot/t

t <- sum(Survive$AC_tot)

Survive$AC_tot/t
```
```{r}
Survive <- Singles |> select(starts_with("M") | starts_with("D") | starts_with("F")) |> rowwise() |> transmute(C1_tot = sum(c_across(ends_with(".1"))), C2_tot = sum(c_across( ends_with(".2"))), C3_tot = sum(c_across(ends_with(".3")))) |> mutate(tot = sum(c_across(everything())))

t <- sum(Survive$tot)

Survive$tot/t

t <- sum(Survive$C1_tot)

Survive$C1_tot/t

t <- sum(Survive$C2_tot)

Survive$C2_tot/t

t <- sum(Survive$C3_tot)

Survive$C3_tot/t

```

```{r}
Survive <- Singles |> select(M.2, D.1, F.2) |> rowwise() |> transmute(C1_tot = sum(c_across(ends_with(".1"))), C2_tot = sum(c_across( ends_with(".2"))), C3_tot = sum(c_across(ends_with(".3")))) |> mutate(tot = sum(c_across(everything())))

t <- sum(Survive$tot)

Survive$tot/t

Survive <- Singles |> select(B.2, AX.1, AC.2) |> rowwise() |> transmute(C1_tot = sum(c_across(ends_with(".1"))), C2_tot = sum(c_across( ends_with(".2"))), C3_tot = sum(c_across(ends_with(".3")))) |> mutate(tot = sum(c_across(everything())))

t <- sum(Survive$tot)

Survive$tot/t

t <- sum(Survive$C1_tot)

Survive$C1_tot/t

t <- sum(Survive$C2_tot)

Survive$C2_tot/t

t <- sum(Survive$C3_tot)

Survive$C3_tot/t

```
```{r}
Survive <- Singles |> select(starts_with("B") | starts_with("A")) |> rowwise() |> transmute(C1_tot = sum(c_across(ends_with(".1"))), C2_tot = sum(c_across( ends_with(".2"))), C3_tot = sum(c_across(ends_with(".3")))) |> mutate(tot = sum(c_across(everything())))

t <- sum(Survive$tot)

Survive$tot/t

t <- sum(Survive$C1_tot)

Survive$C1_tot/t

t <- sum(Survive$C2_tot)

Survive$C2_tot/t

t <- sum(Survive$C3_tot)

Survive$C3_tot/t

```
```{r Testing Vignettes Diff All Cond}
VignData <- Data |>
  transmute(
    YY = YY.1 + YY.2 + YY.3,
    YN = YN.1 + YN.2 + YN.3,
    NY = NY.1 + NY.2 + NY.3,
    NN = NN.1 + NN.2 + NN.3,
    Major = Major.1 + Major.2 + Major.3,
    minor = minor.1 + minor.2 + minor.3
  )

VignData[2,] <- VignData[2,] |>
  mutate(
    YN.1 = NY,
    NY.1 = YN
  ) |>
  mutate(
    YN = YN.1,
    NY = NY.1
  ) |>
  select(-c(YN.1, NY.1))


VignData.12 <- VignData[c(1,2),] |> select(YN, NY) |> as.matrix()
VignData.12
mcnemar.test(VignData.12)
VignData.13 <- VignData[c(1,3),] |> select(YN, NY) |> as.matrix()
VignData.13
mcnemar.test(VignData.13)
VignData.23 <- VignData[c(2,3),] |> select(YN, NY) |> as.matrix()
VignData.23
mcnemar.test(VignData.23)

# Diff for 1 3 and 2 3 (0.05 > p > 0.01) for YN and NY

VignData.12 <- VignData[c(1,2),] |> select(YY, NY) |> as.matrix()
VignData.12
mcnemar.test(VignData.12)
VignData.13 <- VignData[c(1,3),] |> select(YY, NY) |> as.matrix()
VignData.13
mcnemar.test(VignData.13)
VignData.23 <- VignData[c(2,3),] |> select(YY, NY) |> as.matrix()
VignData.23
mcnemar.test(VignData.23)

# Difference between 1 and 2 for YY and NY

VignData.12 <- VignData[c(1,2),] |> select(YN, YY) |> as.matrix()
VignData.12
mcnemar.test(VignData.12)
VignData.13 <- VignData[c(1,3),] |> select(YN, YY) |> as.matrix()
VignData.13
mcnemar.test(VignData.13)
VignData.23 <- VignData[c(2,3),] |> select(YN, YY) |> as.matrix()
VignData.23
mcnemar.test(VignData.23)

# Difference between 1 & 2 as well as 2 3 (0.05 > p > 0.01) for YN YY
```

```{r Testing Vignette Diff C1}
Data.C1[2,] <- Data.C1[2,] |>
  mutate(
    YN.a = NY.1,
    NY.a = YN.1
  ) |>
  mutate(
    YN.1 = YN.a,
    NY.1 = NY.a
  ) |>
  select(-c(YN.a, NY.a))

VignData.12 <- Data.C1[c(1,2),] |> select(YN.1, NY.1) |> as.matrix()
VignData.12
mcnemar.test(VignData.12)
VignData.13 <- Data.C1[c(1,3),] |> select(YN.1, NY.1) |> as.matrix()
VignData.13
mcnemar.test(VignData.13)
VignData.23 <- Data.C1[c(2,3),] |> select(YN.1, NY.1) |> as.matrix()
VignData.23
mcnemar.test(VignData.23)

# All Diff for YN NY

VignData.12 <- Data.C1[c(1,2),] |> select(YY.1, NY.1) |> as.matrix()
VignData.12
mcnemar.test(VignData.12)
VignData.13 <- Data.C1[c(1,3),] |> select(YY.1, NY.1) |> as.matrix()
VignData.13
mcnemar.test(VignData.13)
VignData.23 <- Data.C1[c(2,3),] |> select(YY.1, NY.1) |> as.matrix()
VignData.23
mcnemar.test(VignData.23)

# Differ for 2 3 for YY NY

VignData.12 <- Data.C1[c(1,2),] |> select(YN.1, YY.1) |> as.matrix()
VignData.12
mcnemar.test(VignData.12)
VignData.13 <- Data.C1[c(1,3),] |> select(YN.1, YY.1) |> as.matrix()
VignData.13
mcnemar.test(VignData.13)
VignData.23 <- Data.C1[c(2,3),] |> select(YN.1, YY.1) |> as.matrix()
VignData.23
mcnemar.test(VignData.23)

# All Diff for YN YY

Data.C1[2,] <- Data.C1[2,] |>
  mutate(
    YN.a = NY.1,
    NY.a = YN.1
  ) |>
  mutate(
    YN.1 = YN.a,
    NY.1 = NY.a
  ) |>
  select(-c(YN.a, NY.a))
```
```{r Testing Vignette Diff C2}
Data.C2[2,] <- Data.C2[2,] |>
  mutate(
    YN.a = NY.2,
    NY.a = YN.2
  ) |>
  mutate(
    YN.2 = YN.a,
    NY.2 = NY.a
  ) |>
  select(-c(YN.a, NY.a))

 
VignData.12 <- Data.C2[c(1,2),] |> select(YN.2, NY.2) |> as.matrix()
VignData.12
mcnemar.test(VignData.12)
VignData.13 <- Data.C2[c(1,3),] |> select(YN.2, NY.2) |> as.matrix()
VignData.13
mcnemar.test(VignData.13)
VignData.23 <- Data.C2[c(2,3),] |> select(YN.2, NY.2) |> as.matrix()
VignData.23
mcnemar.test(VignData.23)

# All Diff for YN NY

VignData.12 <- Data.C2[c(1,2),] |> select(YY.2, NY.2) |> as.matrix()
VignData.12
mcnemar.test(VignData.12)
VignData.13 <- Data.C2[c(1,3),] |> select(YY.2, NY.2) |> as.matrix()
VignData.13
mcnemar.test(VignData.13)
VignData.23 <- Data.C2[c(2,3),] |> select(YY.2, NY.2) |> as.matrix()
VignData.23
mcnemar.test(VignData.23)

# All Diff for YY NY

VignData.12 <- Data.C2[c(1,2),] |> select(YN.2, YY.2) |> as.matrix()
VignData.12
mcnemar.test(VignData.12)
VignData.13 <- Data.C2[c(1,3),] |> select(YN.2, YY.2) |> as.matrix()
VignData.13
mcnemar.test(VignData.13)
VignData.23 <- Data.C2[c(2,3),] |> select(YN.2, YY.2) |> as.matrix()
VignData.23
mcnemar.test(VignData.23)

# Diff for 1 2 and 1 3 for YN YY

Data.C2[2,] <- Data.C2[2,] |>
  mutate(
    YN.a = NY.2,
    NY.a = YN.2
  ) |>
  mutate(
    YN.2 = YN.a,
    NY.2 = NY.a
  ) |>
  select(-c(YN.a, NY.a))

```
```{r Testing Vignette Diff C3}
Data.C3[2,] <- Data.C3[2,] |>
  mutate(
    YN.a = NY.3,
    NY.a = YN.3
  ) |>
  mutate(
    YN.3 = YN.a,
    NY.3 = NY.a
  ) |>
  select(-c(YN.a, NY.a))


VignData.12 <- Data.C3[c(1,2),] |> select(YN.3, NY.3) |> as.matrix()
VignData.12
mcnemar.test(VignData.12)
VignData.13 <- Data.C3[c(1,3),] |> select(YN.3, NY.3) |> as.matrix()
VignData.13
mcnemar.test(VignData.13)
VignData.23 <- Data.C3[c(2,3),] |> select(YN.3, NY.3) |> as.matrix()
VignData.23
mcnemar.test(VignData.23)

# Diff for 1 3 and 2 3 for YN NY

VignData.12 <- Data.C3[c(1,2),] |> select(YY.3, NY.3) |> as.matrix()
VignData.12
mcnemar.test(VignData.12)
VignData.13 <- Data.C3[c(1,3),] |> select(YY.3, NY.3) |> as.matrix()
VignData.13
mcnemar.test(VignData.13)
VignData.23 <- Data.C3[c(2,3),] |> select(YY.3, NY.3) |> as.matrix()
VignData.23
mcnemar.test(VignData.23)

# All Diff for YY NY 

VignData.12 <- Data.C3[c(1,2),] |> select(YN.3, YY.3) |> as.matrix()
VignData.12
mcnemar.test(VignData.12)
VignData.13 <- Data.C3[c(1,3),] |> select(YN.3, YY.3) |> as.matrix()
VignData.13
mcnemar.test(VignData.13)
VignData.23 <- Data.C3[c(2,3),] |> select(YN.3, YY.3) |> as.matrix()
VignData.23
mcnemar.test(VignData.23)

# All Diff for YN YY

Data.C3[2,] <- Data.C3[2,] |>
  mutate(
    YN.a = NY.3,
    NY.a = YN.3
  ) |>
  mutate(
    YN.3 = YN.a,
    NY.3 = NY.a
  ) |>
  select(-c(YN.a, NY.a))
```